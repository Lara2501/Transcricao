{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomemodelo = 'Random Forest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caminhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#Folder Inicial\n",
    "path = os.getcwd()\n",
    "\n",
    "#Subpastas\n",
    "pathin = path + '\\\\Entrada\\\\'\n",
    "pathfixo = path + '\\\\Fixo\\\\'\n",
    "pathout = path + '\\\\Saida\\\\'\n",
    "pathparcial = path + '\\\\Parcial\\\\'\n",
    "pathaux = path + '\\\\Auxiliar\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import pickle\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 3000)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from time import gmtime, strftime\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.utils import parallel_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.3\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo a Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 58)\n",
      "(250, 58)\n"
     ]
    }
   ],
   "source": [
    "file = 'Treino'\n",
    "treino = pd.read_pickle(pathparcial + 'Arquivo0 ' + file + '.pkl')\n",
    "\n",
    "file = 'Teste'\n",
    "teste = pd.read_pickle(pathparcial + 'Arquivo0 ' + file + '.pkl')\n",
    "\n",
    "print(treino.shape)\n",
    "print(teste.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 56)\n",
      "(250, 56)\n"
     ]
    }
   ],
   "source": [
    "#Excluindo variaveis que nao serao usadas no modelo\n",
    "y = 'default'\n",
    "id = 'id'\n",
    "\n",
    "Xtr = treino.drop([y, id], axis = 1)\n",
    "colunas = list(Xtr)\n",
    "\n",
    "with open(pathaux + 'Variaveis Modelo ' + nomemodelo + '.pickle', 'wb') as f:\n",
    "    dill.dump((colunas, y), f)\n",
    "\n",
    "Xte = teste[colunas]\n",
    "\n",
    "print(Xtr.shape)\n",
    "print(Xte.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nomemodelo = 'Random Forest'\n",
    "\n",
    "seed = 123\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators': [100, 300, 500, 700],\n",
    "    'min_samples_leaf': [5, 10],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'random_state': [seed]\n",
    "}\n",
    "        \n",
    "estimator = RandomForestClassifier()\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits = 3, n_repeats = 1, random_state = seed)\n",
    "\n",
    "gs = GridSearchCV(estimator = estimator, param_grid = parameters, cv = cv, scoring = 'f1_macro', \n",
    "                  n_jobs = 3, verbose = 1, refit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-12 01:41:02\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend MultiprocessingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  48 out of  48 | elapsed:   15.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-12 01:41:23\n"
     ]
    }
   ],
   "source": [
    "#Rodando GridSearch\n",
    "print(strftime('%Y-%m-%d %H:%M:%S', gmtime()))\n",
    "\n",
    "with parallel_backend('multiprocessing'):\n",
    "    gs.fit(Xtr, treino[y])\n",
    "\n",
    "joblib.dump(gs, pathaux + 'Modelo ' + nomemodelo + '.pkl')\n",
    "\n",
    "print(strftime('%Y-%m-%d %H:%M:%S', gmtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7185572030229127"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'min_samples_leaf': 5,\n",
       " 'n_estimators': 300,\n",
       " 'random_state': 123}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "cvresults = pd.DataFrame(gs.cv_results_)[[\n",
    " 'mean_test_score',\n",
    " 'mean_train_score',\n",
    " 'param_n_estimators',\n",
    " 'param_min_samples_leaf',\n",
    " 'param_class_weight',\n",
    " 'std_test_score',\n",
    " 'std_train_score']]\n",
    "ha = list(cvresults)\n",
    "ha = [w.replace('param_', '') for w in ha]\n",
    "cvresults.columns = ha\n",
    "cvresults.to_excel(pathout + 'Modelo ' + nomemodelo + ' Resultados GridSearch.xlsx', encoding = 'latin1', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.702489</td>\n",
       "      <td>0.847840</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.022517</td>\n",
       "      <td>0.013150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.718557</td>\n",
       "      <td>0.857084</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.029112</td>\n",
       "      <td>0.004529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.705033</td>\n",
       "      <td>0.855882</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.024714</td>\n",
       "      <td>0.001835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.705568</td>\n",
       "      <td>0.853532</td>\n",
       "      <td>700</td>\n",
       "      <td>5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.021391</td>\n",
       "      <td>0.003386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.698039</td>\n",
       "      <td>0.764300</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.036531</td>\n",
       "      <td>0.005392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.684505</td>\n",
       "      <td>0.771813</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.028982</td>\n",
       "      <td>0.005746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.683053</td>\n",
       "      <td>0.771389</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.027615</td>\n",
       "      <td>0.010733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.682456</td>\n",
       "      <td>0.773104</td>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.023204</td>\n",
       "      <td>0.008783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.602121</td>\n",
       "      <td>0.808227</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.035339</td>\n",
       "      <td>0.013786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.598734</td>\n",
       "      <td>0.806410</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.036097</td>\n",
       "      <td>0.014060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.607663</td>\n",
       "      <td>0.809457</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.034584</td>\n",
       "      <td>0.012139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.598525</td>\n",
       "      <td>0.810062</td>\n",
       "      <td>700</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.035060</td>\n",
       "      <td>0.018006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.536788</td>\n",
       "      <td>0.666852</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.023824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.520137</td>\n",
       "      <td>0.653869</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.013179</td>\n",
       "      <td>0.026599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.527994</td>\n",
       "      <td>0.659658</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.018675</td>\n",
       "      <td>0.029449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.527522</td>\n",
       "      <td>0.657525</td>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.019116</td>\n",
       "      <td>0.028761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  mean_train_score n_estimators min_samples_leaf  \\\n",
       "0          0.702489          0.847840          100                5   \n",
       "1          0.718557          0.857084          300                5   \n",
       "2          0.705033          0.855882          500                5   \n",
       "3          0.705568          0.853532          700                5   \n",
       "4          0.698039          0.764300          100               10   \n",
       "5          0.684505          0.771813          300               10   \n",
       "6          0.683053          0.771389          500               10   \n",
       "7          0.682456          0.773104          700               10   \n",
       "8          0.602121          0.808227          100                5   \n",
       "9          0.598734          0.806410          300                5   \n",
       "10         0.607663          0.809457          500                5   \n",
       "11         0.598525          0.810062          700                5   \n",
       "12         0.536788          0.666852          100               10   \n",
       "13         0.520137          0.653869          300               10   \n",
       "14         0.527994          0.659658          500               10   \n",
       "15         0.527522          0.657525          700               10   \n",
       "\n",
       "   class_weight  std_test_score  std_train_score  \n",
       "0      balanced        0.022517         0.013150  \n",
       "1      balanced        0.029112         0.004529  \n",
       "2      balanced        0.024714         0.001835  \n",
       "3      balanced        0.021391         0.003386  \n",
       "4      balanced        0.036531         0.005392  \n",
       "5      balanced        0.028982         0.005746  \n",
       "6      balanced        0.027615         0.010733  \n",
       "7      balanced        0.023204         0.008783  \n",
       "8          None        0.035339         0.013786  \n",
       "9          None        0.036097         0.014060  \n",
       "10         None        0.034584         0.012139  \n",
       "11         None        0.035060         0.018006  \n",
       "12         None        0.033600         0.023824  \n",
       "13         None        0.013179         0.026599  \n",
       "14         None        0.018675         0.029449  \n",
       "15         None        0.019116         0.028761  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvresults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variaveis Importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feature_Importance(mod, nomemodelo, X, y):\n",
    "    many = ['Linear SVM', 'Logistica', 'Naive Bayes']\n",
    "\n",
    "    k = mod.best_estimator_\n",
    "    featurenames = list(X)\n",
    "    \n",
    "    if nomemodelo in many:\n",
    "        #Logistica, SVM, Naive Bayes\n",
    "        Features = pd.DataFrame(k.coef_.tolist())\n",
    "        Features.columns = featurenames\n",
    "        if len(y.unique()) > 2:\n",
    "            Features.index = sorted(y.unique())\n",
    "    else:\n",
    "        #Arvores\n",
    "        Features = pd.DataFrame({'features': featurenames, 'value': k.feature_importances_.tolist()})\n",
    "        \n",
    "    Features.to_excel(pathout + 'Features ' + nomemodelo + '.xlsx', encoding = 'latin1', index = True)\n",
    "    \n",
    "Feature_Importance(mod = gs, nomemodelo = nomemodelo, X = Xtr, y = treino[y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preditos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predtr = gs.best_estimator_.predict(Xtr)\n",
    "predte = gs.best_estimator_.predict(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\laran\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "name = 'Treino'\n",
    "fim = treino[[id, y]]\n",
    "fim['pred'] = predtr\n",
    "\n",
    "fim['Acertou'] = np.where(fim[y] == fim['pred'], 1, 0)\n",
    "fim.to_excel(pathout + 'Modelo ' + nomemodelo + ' Pred ' + name + '.xlsx', encoding = 'latin1', index = False)\n",
    "\n",
    "del fim\n",
    "\n",
    "name = 'Teste'\n",
    "fim = teste[[id, y]]\n",
    "fim['pred'] = predte\n",
    "\n",
    "fim['Acertou'] = np.where(fim[y] == fim['pred'], 1, 0)\n",
    "fim.to_excel(pathout + 'Modelo ' + nomemodelo + ' Pred ' + name + '.xlsx', encoding = 'latin1', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
